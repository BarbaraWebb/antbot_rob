Todo and notes file for Project:

02 / 10 / 17:
todo:
 - Optical flow detection implementation
   > onCvCameraFrame is the main callback method used (everything happens
     in response to a new visual stimulus
   > From here the threads are run
   > Looking at repurposing existing method computeSparseOpicFlow()
     originally used for speed calculation. Not used anywhere else, so
     may be modified.
 
notes:
 - Optical flow paper: http://www.araa.asn.au/acra/acra2005/papers/low.pdf ::CITE::
   > Detect corners using sparse flow and goodFeaturesToTrack
   > Compute range over a series of frames
   > Halt if below some threshold
   > Tune manually

 - Cross correlation matching?

 - Turns out the optical flow as described by Luca isn't actually there
   > Actually I was wrong, it is, but it's not in the flow computation method; it's in the getSpeeds method
 - Seems to be a number of implementations of image rotation/reshaping/remapping


 - Line 2117: if ( Maths.abs( mod((int) currentPointsTotrack.get(i,j)[0] + 12, 90) - mod((int) prevPointsToTrack.get(i,j)[0] + 12, 90)) < 70 ) {...}
   Taking a distance between two x coordinates of points + 12, this is the pixel offset for the left hand side.
   Looks like, if the distance difference between points in the image (mod 90 for image overlap), is greater than 70, then we have enough information to compute
   a flow vector (IMPORTANT FOR OBSTACLES)

 - So, where to implement my stuff?..
   >Can add functions in MainActivity.java - Function for detection? Then work the behaviour into the appropriate threads (i.e. if clear move step else halt)

progress:
- Actually know how the existing stuff works. The method described by Luca IS present despite what I initially thought; he computes the flow vectors manually
- Added menu options and appropriate back-end code
- Have an idea as to how to implement behaviour:
  A low level (instinct level) function running on each frame to check distances using the methods described in the paper linked above


06 / 10 / 17:
- Getting this optical flow off the ground
  >Compute the focus of expansion

- May need to restructure existing OF flow code so sparse code may be used without
  messing with dense code
  
notes:
- Papers for OF: http://www.dgp.toronto.edu/~donovan/stabilization/opticalflow.pdf
                 http://journals.sagepub.com/doi/full/10.5772/5715

progress:
- Code for computing FOE is in place
- Need to look at using this info
		 
08 / 10 / 17:
- Compute velocity of the robot.
  > For this need to build new arduino functions.
  > Unless I can use getSpeedsFromSparse/Dense flow
    - Will try this method first to avoid fiddling with Arduino

- Compute TTC
- Maybe compute image depth
- Build a basic thread to get the robot to detect an obstacle and halt

notes:
- No speed retrieval methods on hardware apparently
  > How was Luca using the encoders???

- No idea what metric my TTC is in, assuming millisecs but could be secs. Check to see
  if V was per second, TTC should be the same.

progress:
- Have now got code for computing TTC, and hence image depth should be ok
  (Depth = TTC * V)

- Have a very simple test thread to check if the system actually works. How to debug this
  I am completely lost. Could try drawing flow arrows and printing debug info to
  the runOnUiThread.

- Debugging on the robot time!

09 / 10 / 17:
- Get code working

notes:
- Running seems inconsistent (Being stupid, make sure arduino is on
  before trying to run)

- Need to use prevPoints, and currentPoints BEFORE they're used for left/right flow

- IMPORTANT: MATRIX MULTIPLICATION IN ANDROID uses Core.gemm() function to do proper matrix dot product


15 / 10 / 17:
notes:
- Not the most productive week, sidetracked by CT.
- Need to fill out this file for every work session; need to know what was happening when I stopped!

progess:
- Currently debugging AntEye, calculation of the FOE is producing strange results
- Computing u and v is fine (results look weird but worry about that later), then when
  added to A, they show strange, erratic values. May be worth a Stack Overflow question God forbid.
  - Would be worth checking b too to make sure the method does what it's suppoesed to.
  - Otherwise, find a solution quickly, too small a problem to hang about over.

16 / 10 / 17:
- Figure out Mat.put() problem (DONE)
  > Matrix indexing is still from 0...
  > Still getting some strange outputs
  > Fixed, due to matrix initialisation + use of pushback
  > Check b, seems fine

- Refactor code for A and b calculations (DONE)
  > double should be float[] (for u and v)
  > remove debug outputs

- Get true FOE (wrap values around axis to get a value) (DONE)

- Work on TTC calculation, look for bugs.

notes:
- Need to be careful with matrix ops, can be finicky
- Should FOE be absolute? Negative FOE x or y does't make sense
  > Not absolute, wrapped, e.g. -2.5 should be 87.5 (subtract from 90 if neg)
    fx = -95
    fx = Math.abs(fx) = 95	
    fx = fx % 90 = 5
    fx = 89 - 5 = 84

- Printing the correct value tends to help when debugging...
- FOE is returning a 2x1 despite output saying it's 1x2 which is strange
  and annoying.

progress:
- Seem to have a working FOE calculation and this is being sucessfully passed
  up the chain to the obstacle detection function

- Aside: Might be a good idea to draw the FOE on screen, look into this

27 / 10 / 17:
- Draw FOE on debug image
- if wrong, then fix
- if looks correct, split image

notes:
- Speed is changing erratically
- OF information for speed is the same as that for FOE, could be causing problems


30 / 10 / 17:

notes:
- Need a way of saccading; idea, compute left and right flow fields
  as Luca did. Then look for FOE in each of these

  [     | .   ]  // Say image is centered at -45 (left flow) FOE should be thereish

  If it's anywhere to the left, then we need to..

  Ok, don't split the frame, just look for FOE, then turn away from it

- Need to figure out how foe would change based on flow field...


06 / 11 / 17:
today:
- Fix movement and stopping commands (DONE)
- TTC gone wild??? WHY?!
  - Soln, take average ttc values (possibly average out the FOE as well.
  - This is getting stupid.
  - Taking average FOE over 5 frames, looks more consistent than before.

notes:
- Lost time due to ADB and weird TTC issues.
- FOE averageing:
  - Init global_foe to (45, 5)
  - FOE is a 2x1, ensure all matrices reflect this, stupid amount of null
    pointer exceptions
  - global_ttc should be just above whatever threshold you are setting
  

10 / 11 / 17:
today:
- Normailize input image

notes:
- RGBA normalisation is making the app noticably slower, this may present an issue.
- Now, only normalize the blue channel for effiency but still slow.

progress:
- Little; normalisation had no noticeable affect on the calculations + behaviour

17 / 11 / 17:
today:
- Draw points on the debug frame, hope to confirm suspicions about
  cvGoodFeaturesToTrack();

- Switch to using dense flow for all optic flow (DONE)
- Move to speed from encoders, either how Luca did it, or from the arduino direct
  
- Test
- Look into creating an optical flow filter as in:
  http://jeb.biologists.org/content/jexbio/213/11/1886.full.pdf

  Looks like a uniform flow filter shifted left and right then overlaid.

notes:
- cvGoodFeaturesToTrack():
  - Movement is being detected where there is none, small but varied
  - Somewhat inconsistant, new features are being picked up and vanishing while
    the robot is sat still. Take images to document.
    - Images taken, better examples could be collected.

- Wheel encoders:
  - It looks like the arduino keeps track of these, but:
    1. Not for the go command. No encoder information is collected or sent
    2. In it's other uses, it is used internally, not sent back, where is this
       message?
    3. Need to find this, otherwise I'm going to have to edit Arduino code which is
       a scary prospect.

- Have not tested

progress:
- Determined that cvGoodFeatures was giving bad/inconsistent information
- Switched flow methods
- Closer to true wheel encoder usage, lord knows what was going on before
- Have an idea of what to do flow filter wise, but need to look into practical
  implementations of such a filter.

20 / 11 / 17:
todo:
- quick tests of new OF
- check Luca's filters for OF against his dissertation to see what he was doing
- figure out how broadcasting and recieving works here, need those encoder values
  and they're not being sent
- Get Leon's email.

notes:
- prevPointsToTrack for some reason not initialised in computeDenseOpticFlow
- prevPointsToTrack not used at all for dense flow
- Testing did not happen due to this

21 / 11 / 17:
todo:
- fix FOE calculation for dense flow (DONE)
- more work on flow filtering

notes:
- old code for computing foe was downright strange, be careful with new stuff
- luca's flow filtering was done using CX_Holonomic.get_prefered_flow() which
  uses his method of projecting the vectors onto a unit circle.
- the left and right preferred flow will be identical as the directional flag is
  never used

  How can I use this?

23 / 11 / 17:
notes:
- Luca's filtering done using the dot product i.e. the projection of the actual
  viewed flow onto the expected.

- TTC now infinite, distances seem more realistic and FOE is consistant
- Need to figure out image depth to use TTC, otherwise also, FLOW FILTERING!!!

24 / 11 / 17:
- Solve Infinite TTC (DONE)
- Filtering: figure it out. (DONE, I think...)
  - How to gain a filter from Luca's code (known, figured out a couple of days ago)
  - How to use this to detect obstacles???
    - For each flow vector detected:
      	  project it onto the expected (dot product)
	  add the result to an accumulator
	  if we exceed some threshold
	  reset and saccade away from the FOE.

- Implement filtering for the purpose of collision avoidance (DONE)

- Look more into the orginal method using the OF paper, convinced I'm missing
  something

notes:
- Infinite TTC caused by fact that speed is less than one when the robot is
  stationary, we divide by speed^distances which comes out as ~0.02^900 -> 0
  Dividing by 0 gives infinity in Java

- Solution?: Could just set speeds to 1 if sufficiently small.
- Could test to see if it drops when actually running the bot.
  - Tests show it does, though not sure how it behaves
  - Answer: strangely. TTC goes from infinite to slightly greater than 0
    in one jump.
  - Problem: As soon as the power was actually computable (big enough to where,
    it wouldn't -> 0), it becomse infinite as you're still going to the power of
    900. Attempted solution was to scale back the power by the same degree that we
    increased the speed, however no joy. It only takes one sufficiently large
    speed reading to throw the whole thing off.
  - May finally be time to accept that this approach will not work.
    
- Maybe remove normalisation for performance
  - Was already off for some reason?
- Moment of realisation when all of my flow filtering code essenially does
  what Luca's already did. So, I feel like I may be computing speed information?

progress:
- Figured out some problems with the old CA approach
- Implemented an OF filter for Collision Avoidance.
- Now need to test with this and tune it to see what thresholds would be
  appropriate.

- Construct a testing environment; observe flow values as obstacles approach on
  either side.

- Still need to send Leo an email to sort out the encoders, but the dense flow
  speed actually looks a lot more consistent.

