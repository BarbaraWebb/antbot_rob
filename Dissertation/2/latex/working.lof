\contentsline {figure}{\numberline {1}{\ignorespaces The Mushroom Body circuit: (Caption from \textit {Ardin et al.}, Figure 2; note, their description and figure uses ``EN'' instead of ``MBON''): Images (see Fig 1) activate the visual projection neurons (vPNs). Each Kenyon cell (KC) receives input from 10 (random) vPNs and exceeds firing threshold only for coincident activation from several vPNs, thus images are encoded as a sparse pattern of KC activation. All KCs converge on a single extrinsic neuron (EN) and if activation coincides with a reward signal, the connection strength is decreased. After training the EN output to previously rewarded (familiar) images is few or no spikes.\relax }}{7}
\contentsline {figure}{\numberline {2}{\ignorespaces (Figure 2 from \cite {Haferlach2007}) The Marker-Based encoding scheme used by \textit {Haferlach et al.}, demonstrating how a simple neural model would be encoded as a sequence of integers.\relax }}{8}
\contentsline {figure}{\numberline {3}{\ignorespaces (Figure 3 from \cite {Haferlach2007}) The high-fitness network, consistently evolved using the constrained two-stage evolution process illustrated by \textit {Haferlach et al.} \relax }}{10}
\contentsline {figure}{\numberline {4}{\ignorespaces The Central Complex model presented by \textit {Stone et al.}. (Left) This graph demonstrates the basic structure of the CX model (Figure 5G from \cite {Stone2017}). Pontine neurons have been excluded for clarity. (Right) This graph shows how signals propogate through the network where the current heading lies to the left of the desired heading, i.e. a right turn should be generated (Figure 5I from \cite {Stone2017}). The numbers given at each layer on the right correspond to the numbers given for each neuron in the graph on the left. \relax }}{11}
\contentsline {figure}{\numberline {5}{\ignorespaces Here we can see the layers of the CX model and how they fit together. A heading signal is input to the TL neurons, propogating through the CL layer to TB1 (heading ring-attractor) and CPU4 (memory). TN neurons (speed sensitivity) input directly to CPU4. So, the combination of heading and speed inputs to CPU4 gives a measure of distance travelled in a particular direction; this facilitates generation of a steering command in CPU1 providing a mechanism for Path Integration. \relax }}{12}
\contentsline {figure}{\numberline {6}{\ignorespaces Our interpretation of the eight MBON model proposed by \textit {Zhang}. Every KC connects to every MBON. All connection weights start out at $w=1$. Following the example presented in the text, if an image being learned corresponds to facing a direction of $45^{\circ }$, then only the conncetions to that MBON (highlighted in red) are eligible to have their weights modified. Recall, however, that these weights will only be modified if the KC was activated (not shown in the figure). \relax }}{15}
\contentsline {figure}{\numberline {7}{\ignorespaces The AntBot, connected to the charging station. This figure also shows the position of the mobile phone, camera attachment, and retroflective motion capture markers on the top of the robot. \relax }}{20}
\contentsline {figure}{\numberline {8}{\ignorespaces The Kogeto Dot 360$^\circ $ panoramic lens attachment.\relax }}{20}
\contentsline {figure}{\numberline {9}{\ignorespaces A sample view of the lens from the front facing camera, before any processing.\relax }}{20}
\contentsline {figure}{\numberline {10}{\ignorespaces The hard-coded centre used for the polar transform (red), against the circle detected using the Hough transform (green). \relax }}{21}
