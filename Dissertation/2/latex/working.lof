\contentsline {figure}{\numberline {1}{\ignorespaces The optical flow filter given by \textit {Scimeca} for speed retrieval, caption by \textit {Scimeca}, Figure 13 (clarifications in square brackets given by \textit {Mitchell} in \cite {Mitchell2018}): Figure (a) shows the idea behind the modiﬁcation of the ﬁlter for speed retrieval. When moving forward, for example, we expect the rectangular 360 [degree] image to have vector ﬂows in diﬀerent length throughout the frame, in the pattern shown in the Figure. Figure (b) shows the ﬁlter response of the modiﬁed ﬁltering process for this [Scimeca’s] project. During matching, the found ﬂow vectors will be projected onto the corresponding ﬁlter vectors nullifying the information on the y axis and scaling the vectors diﬀerently depending on the area of the image they are found in. \relax }}{7}
\contentsline {figure}{\numberline {2}{\ignorespaces The Mushroom Body circuit: (Caption from \textit {Ardin et al.}, Figure 2; note, their description and figure uses ``EN'' instead of ``MBON''): Images (see Fig 1) activate the visual projection neurons (vPNs). Each Kenyon cell (KC) receives input from 10 (random) vPNs and exceeds firing threshold only for coincident activation from several vPNs, thus images are encoded as a sparse pattern of KC activation. All KCs converge on a single extrinsic neuron (EN) and if activation coincides with a reward signal, the connection strength is decreased. After training the EN output to previously rewarded (familiar) images is few or no spikes.\relax }}{9}
\contentsline {figure}{\numberline {3}{\ignorespaces (Figure 2 from \cite {Haferlach2007}) The Marker-Based encoding scheme used by \textit {Haferlach et al.}, demonstrating how a simple neural model would be encoded as a sequence of integers.\relax }}{11}
\contentsline {figure}{\numberline {4}{\ignorespaces (Figure 3 from \cite {Haferlach2007}) The high-fitness network, consistently evolved using the constrained two-stage evolution process illustrated by \textit {Haferlach et al.} \relax }}{13}
\contentsline {figure}{\numberline {5}{\ignorespaces The Central Complex model presented by \textit {Stone et al.} (Left) This graph demonstrates the basic structure of the CX model (Figure 5G from \cite {Stone2017}). Pontine neurons have been excluded for clarity. (Right) This graph shows how signals propogate through the network where the current heading lies to the left of the desired heading, i.e. a right turn should be generated (Figure 5I from \cite {Stone2017}). The numbers given at each layer on the right correspond to the numbers given for each neuron in the graph on the left. \relax }}{14}
\contentsline {figure}{\numberline {6}{\ignorespaces Here we can see the layers of the CX model and how they fit together. A heading signal is input to the TL neurons, propogating through the CL layer to TB1 (heading ring-attractor) and CPU4 (memory). TN neurons (speed sensitivity) input directly to CPU4. So, the combination of heading and speed inputs to CPU4 gives a measure of distance travelled in a particular direction; this facilitates generation of a steering command in CPU1 providing a mechanism for path integration. \relax }}{15}
\contentsline {figure}{\numberline {7}{\ignorespaces Our interpretation of the eight MBON model proposed by \textit {Zhang}. Every KC connects to every MBON. All connection weights start out at $w=1$. Following the example presented in the text, if an image being learned corresponds to facing a direction of $45^{\circ }$, then only the conncetions to that MBON (highlighted in red) are eligible to have their weights modified. Recall, however, that these weights will only be modified if the KC was activated (not shown in the figure). \relax }}{19}
\contentsline {figure}{\numberline {8}{\ignorespaces The AntBot, connected to the charging station. This figure also shows the position of the mobile phone, camera attachment, and retroflective motion capture markers on the top of the robot. \relax }}{23}
\contentsline {figure}{\numberline {9}{\ignorespaces The Kogeto Dot 360$^\circ $ panoramic lens attachment.\relax }}{24}
\contentsline {figure}{\numberline {10}{\ignorespaces A sample view of the lens from the front facing camera, before any processing.\relax }}{24}
\contentsline {figure}{\numberline {11}{\ignorespaces The hard-coded centre used for the polar transform (red), against the circle detected using the Hough transform (green). \relax }}{25}
\contentsline {figure}{\numberline {12}{\ignorespaces Frame 3 from Figure 21\hbox {}. A subset of points from the dense optical flow field observed by the agent. The agent is experiencing forward translational motion. These frames were captured after the framerate improvement from Section 3.3\hbox {}. The FOE is also shown in blue. There are no obstacles present in the arena. \relax }}{30}
\contentsline {figure}{\numberline {13}{\ignorespaces Function of firing rate response of the single ACC neuron against difference input; sigmoid (Eq. 10\hbox {}) with $a = 5$, $b = 0$. The input to this neuron must be scaled down to lie between -1 and 1.\relax }}{32}
\contentsline {figure}{\numberline {14}{\ignorespaces An example of signal propogation and generated output from the rate-based system (left-to-right, top-to-bottom). An example flow input is given as 0.25. The ACC rate response is then put through the offset computation function (Eq. 27\hbox {}). The default sinusoid function is generated over eight array elements. The sinusoid is then shifted such that the maximum lies at \textit {current\textunderscore direction + round(offset)} which in this case is 5. This sinusoid is then extended to a sixteen elements to match the representation in CPU4. Each element of the sinusoid is then supplied as input to the corresponding MRSP neuron to give the rate output in the final plot; as there are two neurons for each cardinal direction, the two maxima indicate a single direction. This MRSP response is used as input to the CPU1 layer, in this example a small right turn will be generated. \relax }}{36}
\contentsline {figure}{\numberline {15}{\ignorespaces A test recording from the Central Complex PI experiments. The agent successfully navigates home but requires a large turning arc to point back towards the nest. This is because the output of the CX is not a precise angle but instead a turn direction with some strength. This behaviour was our prompt and justification to include an about turn on completion of the outbound route; the space present in the arena simply did not permit such routes for formal experiments. \relax }}{38}
\contentsline {figure}{\numberline {16}{\ignorespaces The non-empty arena used for testing the shifting expansion field system. Tussocks were set to the left and right of the robot's trajectory (shown in red) so that they were not on a collision course but should still affect the expansion field. We had hoped the FOE would either remain central or drift horizontally (in a consistent fashion) as each object was passed. Note that the agent was not started directly on the tape square, it was offset as shown by the path; this was oversight on our part. \relax }}{40}
\contentsline {figure}{\numberline {17}{\ignorespaces PI test AB\textunderscore CX\textunderscore 10. This was considered the worst failure of the system despite not having the greatest deviation from the start point.\relax }}{44}
\contentsline {figure}{\numberline {18}{\ignorespaces PI test AB\textunderscore CX\textunderscore 8. Arguably the most successful recording from the formal experiments. The agent still corrects to achieve a better homing path, despite the fact it could likely have travelled in a straight line. \relax }}{44}
\contentsline {figure}{\numberline {19}{\ignorespaces PI test AB\textunderscore CX\textunderscore 1. In this case, we note the exact same experimental flaw we sought to avoid in which the robot requires no correction to home successfully.\relax }}{45}
\contentsline {figure}{\numberline {20}{\ignorespaces Five consecutive image frames with optical flow information superimposed over the top. It can be seen that the FOE position (central pixel of the blue cross) is not consistent across multiple frames. This figure also shows the disturbance caused by approaching a tussock on the right hand side (3rd and 4th frames). Video captured at approximately 10fps (i.e. these images were captured accross roughly 0.5 seconds). \relax }}{46}
\contentsline {figure}{\numberline {21}{\ignorespaces Another set of consecutive frames, this time captured in an environment with no objects present. The FOE is still unpredictable, though it does not move as drastically in the horizontal axis. \relax }}{46}
\contentsline {figure}{\numberline {22}{\ignorespaces PI test AB\textunderscore CX\textunderscore 1\relax }}{61}
\contentsline {figure}{\numberline {23}{\ignorespaces PI test AB\textunderscore CX\textunderscore 2\relax }}{61}
\contentsline {figure}{\numberline {24}{\ignorespaces PI test AB\textunderscore CX\textunderscore 3\relax }}{62}
\contentsline {figure}{\numberline {25}{\ignorespaces PI test AB\textunderscore CX\textunderscore 4\relax }}{62}
\contentsline {figure}{\numberline {26}{\ignorespaces PI test AB\textunderscore CX\textunderscore 5\relax }}{63}
\contentsline {figure}{\numberline {27}{\ignorespaces PI test AB\textunderscore CX\textunderscore 6\relax }}{63}
\contentsline {figure}{\numberline {28}{\ignorespaces PI test AB\textunderscore CX\textunderscore 7\relax }}{64}
\contentsline {figure}{\numberline {29}{\ignorespaces PI test AB\textunderscore CX\textunderscore 8\relax }}{64}
\contentsline {figure}{\numberline {30}{\ignorespaces PI test AB\textunderscore CX\textunderscore 9\relax }}{65}
\contentsline {figure}{\numberline {31}{\ignorespaces PI test AB\textunderscore CX\textunderscore 10\relax }}{65}
